# ======== [1] 네임스페이스 생성 ========
apiVersion: v1
kind: Namespace
metadata:
  name: anotherclass-123 # 네임스페이스 이름
  labels:
    part-of: k8s-anotherclass
    managed-by: dashboard

# ======== [2] Deployment 생성 ========
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: anotherclass-123
  name: api-tester-1231
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: dashboard
spec:
  selector:
    matchLabels:
      part-of: k8s-anotherclass
      component: backend-server
      name: api-tester
      instance: api-tester-1231
  replicas: 2
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        part-of: k8s-anotherclass
        component: backend-server
        name: api-tester
        instance: api-tester-1231
        version: 1.0.0
    spec:
      nodeSelector:
        kubernetes.io/hostname: k8s-master
      containers:
        - name: api-tester-1231
          image: 1pro/api-tester:v1.0.0
          ports:
          - name: http
            containerPort: 8080
          envFrom:
            - configMapRef:
                name: api-tester-1231-properties
            # - secretRef:
            #     name: api-tester-1231-env-mission-1
          startupProbe: # 컨테이너가 정상적으로 시작했는지 확인 (헬스체크로) ~ 이게 완료되면 readiness/liveness 체크
            httpGet:
              path: "/startup"
              port: 8080
            periodSeconds: 5
            failureThreshold: 36
          readinessProbe: # 컨테이너가 트래픽을 받을 준비가 되었는지 확인 (헬스체크로) ~ 통과전까지 트래픽 안받음 (서비스 연결X)
            httpGet:
              path: "/readiness"
              port: 8080
            # exec: api가 아니라, exec 명령어로 헬스체크도 가능
            #   command:
            #     - test
            #     - -f
            #     - /usr/src/myapp/datasource/postgresql-info.yaml
            # 이 외에, tcpSocket (원하는 포트로 TCP 요청), grpc 등도 가능
            periodSeconds: 10
            failureThreshold: 3
          livenessProbe: # 컨테이너가 정상적으로 동작하고 있는지 확인 (헬스체크로) ~ 갑자기 비정상 상태 되면 재시작함
            httpGet:
              path: "/liveness"
              port: 8080
            periodSeconds: 10
            failureThreshold: 3
          resources:
            requests:
              memory: "100Mi"
              cpu: "100m"
            limits:
              memory: "200Mi"
              cpu: "200m"
          volumeMounts:
            - name: files
              mountPath: /usr/src/myapp/files/dev
            - name: secret-datasource
              mountPath: /usr/src/myapp/datasource
            # - name: configmap-datasource
            #   mountPath: /usr/src/myapp/datasource
      volumes: # 볼륨 오브젝트와 연결해 컨테이너에서 사용할 수 있도록 함
        - name: files
          persistentVolumeClaim:
            claimName: api-tester-1231-files
        - name: secret-datasource
          secret:
            secretName: api-tester-1231-postgresql
        # - name: configmap-datasource
        #   configMap:
        #     name: api-tester-1231-configmap-to-file

# ======== [3] Service 생성 ========
apiVersion: v1
kind: Service
metadata:
  namespace: anotherclass-123
  name: api-tester-1231
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: dashboard
spec:
  selector:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
  ports:
    - port: 80 # 클러스터 내부에서 80 포트로 접근 가능
      targetPort: http
      nodePort: 31231 # 외부에서 31231 포트로 접근 가능하게함
  type: NodePort # NodePort 타입으로 설정하여 외부에서 접근 가능하게 함
   # NodePort: 클러스터 외부에서 접근할 수 있도록 노드의 특정 포트를 열어주는 방식
   # 31231 > 80 으로 받고 service가 8080 으로 로드밸런싱

# ======== [4] ConfigMap 및 Secret 생성 ========
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: anotherclass-123
  name: api-tester-1231-properties
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: dashboard
data:
  spring_profiles_active: "dev"
  application_role: "ALL"
  postgresql_filepath: "/usr/src/myapp/datasource/postgresql-info.yaml"
  # postgresql-info.yaml: | ~ 이렇게 파일형태 저장도 가능
  #   driver-class-name: "org.postgresql.Driver"
  #   url: "jdbc:postgresql://postgresql:5431"
  #   username: "dev"
  #   password: "dev123"
  #   mission: "5-2-configmap-to-file"
---
apiVersion: v1
kind: Secret # 파일형태 또는 환경변수로 민감 정보 저장 ~ 기본적으로 base64인코딩만 함
metadata:
  namespace: anotherclass-123
  name: api-tester-1231-postgresql
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: dashboard
stringData: # postgresql-info.yaml 파일로 생성
  postgresql-info.yaml: |
    driver-class-name: "org.postgresql.Driver"
    url: "jdbc:postgresql://postgresql:5431"
    username: "dev"
    password: "dev123"
# stringData: ~ 이렇게 env 주입도 가능
#   spring_profiles_active: "dev"
#   application_role: "ALL"
#   postgresql_filepath: "/usr/src/myapp/datasource/postgresql-info.yaml"
#   mission: "5-1-secret-to-env"

# ======== [5] PVC, PV 생성 ========
apiVersion: v1
kind: PersistentVolumeClaim # 네임스페이스 레벨에서 생성하는 스토리지 요청 (Pod가 필요한 스토리지 용량/속성) 정의
# PVC가 생성되면, 쿠버네티스가 조건에 맞는 영구 저장 볼륨(PV)을 찾아 자동으로 연결(binding)
  # selector/labels가 일치하고, PVC의 accessModes, storage 용량 등이 PV의 것에 포함되어야.
metadata:
  namespace: anotherclass-123
  name: api-tester-1231-files
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: kubectl
spec:
  resources:
    requests:
      storage: 2G
  accessModes:
    - ReadWriteMany
  selector:
    matchLabels: # 특정 라벨의 PV와 바인딩
      part-of: k8s-anotherclass
      component: backend-server
      name: api-tester
      instance: api-tester-1231-files
---
apiVersion: v1
kind: PersistentVolume # 클러스터레벨에서 생성하는 영구저장 스토리지 타입 정의
# 실제 2GB 로컬 디스크(/root/k8s-local-volume/1231) 제공
# 영구저장 스토리지 (PV) 이외 NFS, 로컬디스크, 클라우드 디스크 타입 등이 있다고 함 ~ 아마 Deployment > template 에서 지정하려나?
metadata:
  name: api-tester-1231-files
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231-files
    version: 1.0.0
    managed-by: dashboard
spec:
  capacity:
    storage: 2G
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  local:
    path: "/root/k8s-local-volume/1231"
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - {key: kubernetes.io/hostname, operator: In, values: [k8s-master]}

# ======== [5] HPA 생성 (Horizontal Pod Autoscaler) ========
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  namespace: anotherclass-123
  name: api-tester-1231-default
  labels:
    part-of: k8s-anotherclass
    component: backend-server
    name: api-tester
    instance: api-tester-1231
    version: 1.0.0
    managed-by: dashboard
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-tester-1231
  minReplicas: 2
  maxReplicas: 4
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 60
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 120



# configmap 조회
kubectl get -n anotherclass-123 configmaps api-tester-1231-properties -o yaml
kubectl get -n anotherclass-123 configmaps api-tester-1231-properties -o jsonpath='{.data}'
# secret 조회
kubectl get -n anotherclass-123 secret api-tester-1231-postgresql -o yaml
kubectl get -n anotherclass-123 secret api-tester-1231-postgresql -o jsonpath='{.data}'
kubectl get -n anotherclass-123 secret api-tester-1231-postgresql -o jsonpath='{.data.postgresql-info\.yaml}' | base64 -d
# pod 내부 실행해서 조회
kubectl exec -n anotherclass-123 -it api-tester-1231-9877784b7-vlswd -- env

